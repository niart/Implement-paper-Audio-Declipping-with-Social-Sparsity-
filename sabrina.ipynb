{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change backbone to MobileNet\n",
    "### First, setup libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, Subset\n",
    "\n",
    "# A module to print a model summary (outputs shape, number of parameters, ...)\n",
    "import torchsummary\n",
    "\n",
    "# TensorBoard for visualization\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from tensorboardX import SummaryWriter\n",
    "tensorboard = SummaryWriter()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "# plt.rcParams['text.usetex'] = True  # Render Matplotlib text with Tex\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import cv2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data to be used\n",
    "DATASET = \"./datasets/dataset_3+8bags_3var3sc/\"\n",
    "\n",
    "\n",
    "class TraversabilityDataset(Dataset):\n",
    "    \"\"\"Custom Dataset class to represent our dataset\n",
    "    It includes data and information about the data\n",
    "\n",
    "    Args:\n",
    "        Dataset (class): Abstract class which represents a dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, traversal_costs_file, images_directory,\n",
    "                 transform=None):\n",
    "        \"\"\"Constructor of the class\n",
    "\n",
    "        Args:\n",
    "            traversal_costs_file (string): Path to the csv file which contains\n",
    "            images index and their associated traversal cost\n",
    "            images_directory (string): Directory with all the images\n",
    "            transform (callable, optional): Transforms to be applied on a\n",
    "            sample. Defaults to None.\n",
    "        \"\"\"\n",
    "        # Read the csv file\n",
    "        self.traversal_costs_frame = pd.read_csv(traversal_costs_file)\n",
    "        \n",
    "        # Initialize the name of the images directory\n",
    "        self.images_directory = images_directory\n",
    "        \n",
    "        # Initialize the transforms\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the size of the dataset\n",
    "\n",
    "        Returns:\n",
    "            int: Number of samples\n",
    "        \"\"\"\n",
    "        # Count the number of files in the image directory\n",
    "        # return len(os.listdir(self.images_directory))\n",
    "        return len(self.traversal_costs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Allow to access a sample by its index\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of a sample\n",
    "\n",
    "        Returns:\n",
    "            list: Sample at index idx\n",
    "            ([image, traversal_cost])\n",
    "        \"\"\"\n",
    "        # Get the image name at index idx\n",
    "        image_name = os.path.join(self.images_directory,\n",
    "                                  self.traversal_costs_frame.loc[idx, \"image_id\"])\n",
    "        \n",
    "        # Read the image\n",
    "        image = Image.open(image_name)\n",
    "        \n",
    "        # Eventually apply transforms to the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get the corresponding traversal cost\n",
    "        traversal_cost = self.traversal_costs_frame.loc[idx, \"traversal_cost\"]\n",
    "        \n",
    "        # Get the corresponding traversability label\n",
    "        traversability_label = self.traversal_costs_frame.loc[idx, \"traversability_label\"]\n",
    "\n",
    "        return image, traversal_cost, traversability_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(images_directory, traversal_costs_file):\n",
    "    transform = transforms.Compose([\n",
    "        # Reduce the size of the images\n",
    "        # (if size is an int, the smaller edge of the\n",
    "        # image will be matched to this number and the ration is kept)\n",
    "        transforms.Resize((70, 210)),\n",
    "\n",
    "        # Convert a PIL Image or numpy.ndarray to tensor\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # Create a Dataset for training\n",
    "    dataset = TraversabilityDataset(\n",
    "        traversal_costs_file=DATASET+traversal_costs_file,\n",
    "        images_directory=DATASET+images_directory,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=12,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    cnt = 0\n",
    "    first_moment = torch.empty(3)\n",
    "    second_moment = torch.empty(3)\n",
    "\n",
    "    for images, traversal_costs, traversability_labels in loader:\n",
    "        b, c, h, w = images.shape\n",
    "        nb_pixels = b * h * w\n",
    "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
    "        sum_of_square = torch.sum(images ** 2, dim=[0, 2, 3])\n",
    "        first_moment = (cnt * first_moment + sum_) / (cnt + nb_pixels)\n",
    "        second_moment = (cnt * second_moment + sum_of_square) / (cnt + nb_pixels)\n",
    "        cnt += nb_pixels\n",
    "\n",
    "    mean = first_moment\n",
    "    std = torch.sqrt(second_moment - first_moment ** 2)\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3426, 0.3569, 0.2914]) tensor([0.1363, 0.1248, 0.1302])\n"
     ]
    }
   ],
   "source": [
    "mean, std = compute_mean_std(\"images_train\", \"traversal_costs_train.csv\")\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose several transforms together to be applied to training data\n",
    "# (Note that transforms are not applied yet)\n",
    "train_transform = transforms.Compose([\n",
    "    # Reduce the size of the images\n",
    "    # (if size is an int, the smaller edge of the\n",
    "    # image will be matched to this number and the ration is kept)\n",
    "    # transforms.Resize(100),\n",
    "    transforms.Resize((70, 210)),\n",
    "    \n",
    "    # Perform horizontal flip of the image with a probability of 0.5\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    \n",
    "    # Modify the brightness and the contrast of the image\n",
    "    transforms.ColorJitter(contrast=0.5, brightness=0.5),\n",
    "    \n",
    "    # Convert a PIL Image or numpy.ndarray to tensor\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # Add some random gaussian noise to the image\n",
    "    transforms.Lambda(lambda x: x + (0.001**0.5)*torch.randn(x.shape)),\n",
    "    \n",
    "    # Normalize a tensor image with pre-computed mean and standard deviation\n",
    "    # (based on the data used to train the model(s))\n",
    "    # (be careful, it only works on torch.*Tensor)\n",
    "    transforms.Normalize(\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        # mean=[0.485, 0.456, 0.406],\n",
    "        # std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Define a different set of transforms testing\n",
    "# (for instance we do not need to flip the image)\n",
    "test_transform = transforms.Compose([\n",
    "    # transforms.Resize(100),\n",
    "    transforms.Resize((70, 210)),\n",
    "    # transforms.Grayscale(),\n",
    "    # transforms.CenterCrop(100),\n",
    "    # transforms.RandomCrop(100),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # Mean and standard deviation were pre-computed on the training data\n",
    "    # (on the ImageNet dataset)\n",
    "    transforms.Normalize(\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        # mean=[0.485, 0.456, 0.406],\n",
    "        # std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "# # Create a Dataset instance for our training data\n",
    "# data = TraversabilityDataset(\n",
    "#     traversal_costs_file=DATASET+\"traversal_costs.csv\",\n",
    "#     images_directory=DATASET+\"images\",\n",
    "#     transform=train_transform\n",
    "# )\n",
    "\n",
    "# # Split our training dataset into a training dataset and a validation dataset\n",
    "# train_set, val_set, test_set = random_split(data, [0.8, 0.1, 0.1])\n",
    "\n",
    "\n",
    "# Create a Dataset for training\n",
    "train_set = TraversabilityDataset(\n",
    "    traversal_costs_file=DATASET+\"traversal_costs_train.csv\",\n",
    "    images_directory=DATASET+\"images_train\",\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# Create a Dataset for validation\n",
    "val_set = TraversabilityDataset(\n",
    "    traversal_costs_file=DATASET+\"traversal_costs_train.csv\",\n",
    "    images_directory=DATASET+\"images_train\",\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# Create a Dataset for testin\n",
    "test_set = TraversabilityDataset(\n",
    "    traversal_costs_file=DATASET+\"traversal_costs_test.csv\",\n",
    "    images_directory=DATASET+\"images_test\",\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# Set the train dataset size\n",
    "# 70% of the total data is used for training, 15% for validation\n",
    "# and 15% for testing\n",
    "train_size = 70/(100-15)\n",
    "\n",
    "# Splits train data indices into train and validation data indices\n",
    "train_indices, val_indices = train_test_split(range(len(train_set)), train_size=train_size)\n",
    "\n",
    "# Extract the corresponding subsets of the train dataset\n",
    "train_set = Subset(train_set, train_indices)\n",
    "val_set = Subset(val_set, val_indices)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Combine a dataset and a sampler, and provide an iterable over the dataset\n",
    "# (setting shuffle argument to True calls a RandomSampler, and avoids to\n",
    "# have to create a Sampler object)\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=12,  # Asynchronous data loading and augmentation\n",
    "    pin_memory=True,  # Increase the transferring speed of the data to the GPU\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=12,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,  # SequentialSampler\n",
    "    num_workers=12,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of samples per split\n",
    "NB_TRAIN = len(train_set)\n",
    "NB_VAL = len(val_set)\n",
    "NB_TEST = len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0 % of the data for training (6239 samples)\n",
      "15.0 % of the data for validation (1337 samples)\n",
      "15.0 % of the data for testing (1338 samples)\n"
     ]
    }
   ],
   "source": [
    "# Display the splits ratio\n",
    "NB_SAMPLES = NB_TRAIN + NB_VAL + NB_TEST\n",
    "\n",
    "print(f\"{np.round(NB_TRAIN/NB_SAMPLES*100)} % of the data for training ({NB_TRAIN} samples)\")\n",
    "print(f\"{np.round(NB_VAL/NB_SAMPLES*100)} % of the data for validation ({NB_VAL} samples)\")\n",
    "print(f\"{np.round(NB_TEST/NB_SAMPLES*100)} % of the data for testing ({NB_TEST} samples)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a GPU if available\n",
    "# device = \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model design and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /home/student/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
      "100%|██████████| 9.83M/9.83M [00:00<00:00, 109MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvNormActivation(\n",
      "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): ConvNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): ConvNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "    (1): Hardswish()\n",
      "    (2): Dropout(p=0.2, inplace=True)\n",
      "    (3): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Load the pre-trained MobileNetV3 model\n",
    "model = models.mobilenet_v3_small(pretrained=True).to(device=device)\n",
    "\n",
    "# Replace the last layer by a fully-connected one with 1 output\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 1).to(device=device)\n",
    "\n",
    "# Initialize the last layer using Xavier initialization\n",
    "nn.init.xavier_uniform_(model.classifier[3].weight)\n",
    "\n",
    "# Get all the parameters except for the last layer's weight and bias\n",
    "base_params = [param for name, param in model.named_parameters()\n",
    "               if name != \"classifier.3.weight\" and name != \"classifier.3.bias\"]\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 [train]:  46%|████▌     | 90/195 [00:02<00:02, 37.76batch/s, batch_loss=0.226]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m train_loader_pbar\u001b[39m.\u001b[39mset_postfix(batch_loss\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     57\u001b[0m \u001b[39m# Perform backpropagation (update weights)\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     60\u001b[0m \u001b[39m# Adjust parameters based on gradients\u001b[39;00m\n\u001b[1;32m     61\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the optimizer, with a greater learning rate for the new last layer\n",
    "optimizer = optim.SGD([\n",
    "    {\"params\": base_params},\n",
    "    {\"params\": model.classifier[3].parameters(), \"lr\": 1e-3},\n",
    "],\n",
    "    lr=1e-3, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "# An epoch is one complete pass of the training dataset through the network\n",
    "NB_EPOCHS = 100\n",
    "\n",
    "# Number of epochs we wait for the loss to decrease before stopping\n",
    "# the training process early\n",
    "patience = 10\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "loss_values = torch.zeros(2, NB_EPOCHS)\n",
    "\n",
    "# Loop over the epochs\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    \n",
    "    # Training\n",
    "    train_loss = 0.\n",
    "    \n",
    "    # Configure the model for training\n",
    "    # (good practice, only necessary if the model operates differently for\n",
    "    # training and validation)\n",
    "    model.train()\n",
    "    \n",
    "    # Add a progress bar\n",
    "    train_loader_pbar = tqdm(train_loader, unit=\"batch\")\n",
    "    \n",
    "    # Loop over the training batches\n",
    "    for images, traversal_costs, _ in train_loader_pbar:\n",
    "        \n",
    "        # Print the epoch and training mode\n",
    "        train_loader_pbar.set_description(f\"Epoch {epoch} [train]\")\n",
    "        \n",
    "        # Move images and traversal scores to GPU (if available)\n",
    "        images = images.to(device)\n",
    "        traversal_costs = traversal_costs.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        # Zero out gradients before each backpropagation pass, to avoid that\n",
    "        # they accumulate\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform forward pass\n",
    "        predicted_traversal_costs = model(images)\n",
    "        \n",
    "        # Compute loss \n",
    "        loss = criterion(predicted_traversal_costs[:, 0], traversal_costs)\n",
    "        \n",
    "        # Print the batch loss next to the progress bar\n",
    "        train_loader_pbar.set_postfix(batch_loss=loss.item())\n",
    "        \n",
    "        # Perform backpropagation (update weights)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Adjust parameters based on gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate batch loss to average over the epoch\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0.\n",
    "    \n",
    "    # Configure the model for testing\n",
    "    # (turn off dropout layers, batchnorm layers, etc)\n",
    "    model.eval()\n",
    "    \n",
    "    # Add a progress bar\n",
    "    val_loader_pbar = tqdm(val_loader, unit=\"batch\")\n",
    "    \n",
    "    # Turn off gradients computation (the backward computational graph is built during\n",
    "    # the forward pass and weights are updated during the backward pass, here we avoid\n",
    "    # building the graph)\n",
    "    with torch.no_grad():\n",
    "        # Loop over the validation batches\n",
    "        for images, traversal_costs, _ in val_loader_pbar:\n",
    "\n",
    "            # Print the epoch and validation mode\n",
    "            val_loader_pbar.set_description(f\"Epoch {epoch} [val]\")\n",
    "\n",
    "            # Move images and traversal scores to GPU (if available)\n",
    "            images = images.to(device)\n",
    "            traversal_costs = traversal_costs.type(torch.FloatTensor).to(device)\n",
    "            \n",
    "            # Perform forward pass (only, no backpropagation)\n",
    "            predicted_traversal_costs = model(images)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(predicted_traversal_costs[:, 0], traversal_costs)\n",
    "            # Print the batch loss next to the progress bar\n",
    "            val_loader_pbar.set_postfix(batch_loss=loss.item())\n",
    "\n",
    "            # Accumulate batch loss to average over the epoch\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    \n",
    "    # Compute the losses\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    print(\"Train loss: \", train_loss)\n",
    "    print(\"Validation loss: \", val_loss)\n",
    "    \n",
    "    # Store the computed losses\n",
    "    loss_values[0, epoch] = train_loss\n",
    "    loss_values[1, epoch] = val_loss\n",
    "    \n",
    "    # Add the losses to TensorBoard\n",
    "    tensorboard.add_scalar(\"train_loss\", train_loss, epoch)\n",
    "    tensorboard.add_scalar(\"val_loss\", val_loss, epoch)\n",
    "    \n",
    "    # Early stopping based on validation loss: stop the training if the\n",
    "    # loss has not improved for the last 5 epochs\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    elif epoch - best_epoch >= patience:\n",
    "        print(f'Early stopping at epoch {epoch}')\n",
    "        break\n",
    "\n",
    "# Close TensorBoard\n",
    "tensorboard.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['text.usetex'] = False\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loss\n",
    "indices = loss_values[0] != 0\n",
    "train_losses = loss_values[0][indices]\n",
    "val_losses = loss_values[1][indices]\n",
    "\n",
    "plt.plot(train_losses, label=\"train loss\")\n",
    "plt.plot(val_losses, label=\"validation loss\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Losses (MSE)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "test_loss = 0.\n",
    "\n",
    "# Configure the model for testing\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Loop over the testing batches\n",
    "    for images, traversal_costs, _ in test_loader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        traversal_costs = traversal_costs.to(device)\n",
    "        \n",
    "        # Perform forward pass\n",
    "        predicted_traversal_costs = model(images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(predicted_traversal_costs[:, 0], traversal_costs)\n",
    "        \n",
    "        # Accumulate batch loss to average of the entire testing set\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "# Compute the loss and accuracy\n",
    "test_loss /= len(test_loader)\n",
    "\n",
    "print(\"Test loss: \", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, traversal_costs, _ = next(iter(test_loader))\n",
    "\n",
    "images = images.to(device)\n",
    "traversal_costs = traversal_costs.to(device)\n",
    "\n",
    "predicted_traversal_scores = model(images)\n",
    "# predicted_traversal_scores = nn.Softmax(dim=1)(model(images))\n",
    "\n",
    "print(\"Output:\\n\", predicted_traversal_costs)\n",
    "print(\"Ground truth:\\n\", traversal_costs)\n",
    "\n",
    "# print(predicted_traversal_scores-traversal_scores)\n",
    "\n",
    "# predicted_traversal_scores = predicted_traversal_scores.to(\"cpu\").detach().numpy()\n",
    "# plt.hist(predicted_traversal_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traversal_costs_train = []\n",
    "\n",
    "for _, score, _ in train_set:\n",
    "    traversal_costs_train.append(score)\n",
    "    \n",
    "plt.hist(traversal_costs_train, bins=10)\n",
    "plt.xlabel(\"Traversal Cost\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of Traversal Costs (Training Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model parameters\n",
    "torch.save(model.state_dict(), \"mobilenet.params\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b41780248731413e84842f51b5f7cba9458d17cab322c1e6e009edd67950520d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
